{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bb5852",
   "metadata": {},
   "source": [
    "# Enable distributed tracing with OpenTelemetry.\n",
    "\n",
    "When using distributed agents, it is useful to gather information from all the involved components. In this cookbook, we wil leverage on using A2A agents as tools as demonstrated in [\"Use an Agent as a tool for another agent\"](./../a2a_as_tool) to obtain traces from different components and have a consistent view of a distirbuted trace.\n",
    "\n",
    "First, a Grafana Tempo instance needs to be running in your environment. A good starting point is the [quick start for tempo](https://grafana.com/docs/tempo/latest/getting-started/docker-example/), removing the `k6-tracing` component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e333bc",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "any-agent uses the python asyncio module to support async functionality. When running in Jupyter notebooks, this means we need to enable the use of nested event loops. We'll install any-agent and enable this below using nest_asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100774ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install 'any-agent[a2a]'\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2058da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "from getpass import getpass\n",
    "\n",
    "# This notebook communicates with OpenAI GPT models using the OpenAI API.\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"OPENAI_API_KEY not found in environment!\")\n",
    "    api_key = getpass(\"Please enter your OPENAI_API_KEY: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    print(\"OPENAI_API_KEY set for this session!\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY found in environment.\")\n",
    "    \n",
    "from opentelemetry.trace import get_tracer_provider, TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, BatchSpanProcessor\n",
    "from opentelemetry.sdk.trace.export import ConsoleSpanExporter\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "\n",
    "from any_agent import AgentConfig, AnyAgent, AgentFramework\n",
    "from any_agent.tools import a2a_tool_async\n",
    "from any_agent.serving import A2AServingConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715a289",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "agent_framework = AgentFramework.OPENAI\n",
    "agent_model = \"gpt-4.1-nano\"\n",
    "\n",
    "# Add another trace exporter\n",
    "tp = get_tracer_provider()\n",
    "full_exporter = ConsoleSpanExporter()\n",
    "http_exporter = OTLPSpanExporter(endpoint=\"http://localhost:4318/v1/traces\")\n",
    "tp.add_span_processor(SimpleSpanProcessor(http_exporter))\n",
    "\n",
    "main_agent = None\n",
    "served_agent = None\n",
    "served_task = None\n",
    "served_server = None\n",
    "\n",
    "async def wait_for_server_async(\n",
    "    server_url: str, max_attempts: int = 20, poll_interval: float = 0.5\n",
    "):\n",
    "    attempts = 0\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        while True:\n",
    "            try:\n",
    "                # Try to make a basic GET request to check if server is responding\n",
    "                await client.get(server_url, timeout=1.0)\n",
    "                return  # noqa: TRY300\n",
    "            except (httpx.RequestError, httpx.TimeoutException):\n",
    "                # Server not ready yet, continue polling\n",
    "                pass\n",
    "\n",
    "            await asyncio.sleep(poll_interval)\n",
    "            attempts += 1\n",
    "            if attempts >= max_attempts:\n",
    "                msg = f\"Could not connect to {server_url}. Tried {max_attempts} times with {poll_interval} second interval.\"\n",
    "                raise ConnectionError(msg)\n",
    "\n",
    "try:\n",
    "    tool_agent_endpoint = \"tool_agent\"\n",
    "    test_port = 9999\n",
    "\n",
    "    # DATE AGENT\n",
    "\n",
    "    import datetime\n",
    "\n",
    "    def get_datetime() -> str:\n",
    "        \"\"\"Return the current date and time\"\"\"\n",
    "        return str(datetime.datetime.now())\n",
    "\n",
    "    date_agent_description = \"Agent that can return the current date.\"\n",
    "    date_agent_cfg = AgentConfig(\n",
    "        instructions=\"Use the available tools to obtain additional information to answer the query.\",\n",
    "        name=\"date_agent\",\n",
    "        model_id=agent_model,\n",
    "        description=date_agent_description,\n",
    "        tools=[get_datetime],\n",
    "    )\n",
    "    date_agent = await AnyAgent.create_async(\n",
    "        agent_framework=agent_framework,\n",
    "        agent_config=date_agent_cfg,\n",
    "    )\n",
    "\n",
    "    served_agent = date_agent\n",
    "    (served_task, served_server) = await served_agent.serve_async(\n",
    "        serving_config=A2AServingConfig(\n",
    "            port=test_port,\n",
    "            endpoint=f\"/{tool_agent_endpoint}\",\n",
    "            log_level=\"info\",\n",
    "        )\n",
    "    )\n",
    "    server_url = f\"http://localhost:{test_port}/{tool_agent_endpoint}\"\n",
    "    await wait_for_server_async(server_url)\n",
    "\n",
    "    # Search agent is ready for card resolution\n",
    "\n",
    "    main_agent_cfg = AgentConfig(\n",
    "        instructions=\"Use the available tools to obtain additional information to answer the query.\",\n",
    "        name=\"main_agent\",\n",
    "        model_id=agent_model,\n",
    "        description=\"The orchestrator that can use other agents via tools using the A2A protocol.\",\n",
    "        tools=[await a2a_tool_async(server_url, http_kwargs={\"timeout\": 10.0})],\n",
    "    )\n",
    "\n",
    "    main_agent = await AnyAgent.create_async(\n",
    "        agent_framework=agent_framework,\n",
    "        agent_config=main_agent_cfg,\n",
    "    )\n",
    "\n",
    "    DATE_PROMPT = (\n",
    "        \"What date and time is it right now? \"\n",
    "        \"In your answer please include the year, month, day, and time. \"\n",
    "        \"Example answer could be something like 'Today is December 15, 2024'\"\n",
    "    )\n",
    "    agent_trace = await main_agent.run_async(DATE_PROMPT)\n",
    "\n",
    "    print(agent_trace.final_output)\n",
    "\n",
    "finally:\n",
    "    if served_server:\n",
    "        served_server.should_exit = True\n",
    "        await served_task\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
