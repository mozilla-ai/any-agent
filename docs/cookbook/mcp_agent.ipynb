{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an agent with MCP\n",
    "\n",
    "The [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) (MCP) introduced by Anthropic has proven to be a popular method for providing an AI agent with access to a variety of tools. [This Huggingface blog post ](https://huggingface.co/blog/Kseniase/mcp) has a nice explanation of MCP.  In this tutorial, we'll build an agent that is able to leverage MCP server provided tools.\n",
    "\n",
    "Note: because this tutorial relies upon advanced stdio/stderr communication using the MCP Server, it cannot be run on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "any-agent uses the python asyncio module to support async functionality. When running in Jupyter notebooks, this means we need to enable the use of nested event loops. We'll install any-agent and enable this below using nest_asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'any-agent'\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Agent\n",
    "\n",
    "Now it's time to configure the agent! At this stage you have a few choices:\n",
    "\n",
    "### Pick the framework\n",
    "\n",
    "We support a variety of underlying agent frameworks (OpenAI, Smolagents, Langchain, TinyAgent, etc), which all have their own particular agentic AI implementations. For this tutorial's simple use case, any of the frameworks should work just fine, but any-agent makes it easy to try out a different framework later, if we so choose. For this example, we will use the [TinyAgent](frameworks/tinyagent.md) framework.  \n",
    "\n",
    "### Pick an LLM\n",
    "\n",
    "Regardless of which agent framework you choose, each framework supports any-llm, which is a proxy that allows us to use whichever LLM inside the framework, hosted on by any provider. For example, we could use a local model via llama.cpp or llamafile, a google hosted gemini model, or a AWS bedrock hosted Llama model. For this example, let's use Mistral AI's mistral:mistral-small-latest.\n",
    "\n",
    "### Pick which tools to use\n",
    "\n",
    " In this example, we'll add a few MCP servers that we host locally, which means we'll use a Stdio MCP server. If an MCP Server is already running and hosted elsewhere, you can use an SSE connection to access it. You can browse some of the officially supported MCP servers [here](https://github.com/modelcontextprotocol/servers/tree/main?tab=readme-ov-file).\n",
    "\n",
    " Lets give use two MCP servers: \n",
    " \n",
    " * [Time](https://github.com/modelcontextprotocol/servers/tree/main/src/time): so the agent can know what time/day it is.\n",
    " * [Airbnb](https://github.com/openbnb-org/mcp-server-airbnb): so the agent can browse airbnb listings\n",
    "\n",
    " I will also add a custom send_message tool, that way it can ask us additional questions before getting its final answer!\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"MISTRAL_API_KEY\" not in os.environ:\n",
    "    print(\"MISTRAL_API_KEY not found in environment!\")\n",
    "    api_key = getpass(\"Please enter your MISTRAL_API_KEY: \")\n",
    "    os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
    "    print(\"MISTRAL_API_KEY set for this session!\")\n",
    "else:\n",
    "    print(\"MISTRAL_API_KEY found in environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_agent import AgentConfig, AnyAgent\n",
    "from any_agent.config import MCPStdio\n",
    "\n",
    "# This MCP Tool relies upon uvx https://docs.astral.sh/uv/getting-started/installation/\n",
    "time_tool = MCPStdio(\n",
    "    command=\"uvx\",\n",
    "    args=[\"mcp-server-time\", \"--local-timezone=America/New_York\"],\n",
    "    tools=[\n",
    "        \"get_current_time\",\n",
    "    ],\n",
    "    client_session_timeout_seconds=30,\n",
    ")\n",
    "\n",
    "# This MCP tool relies upon npx https://docs.npmjs.com/cli/v8/commands/npx which comes standard with npm\n",
    "airbnb_tool = MCPStdio(\n",
    "    command=\"npx\",\n",
    "    args=[\"-y\", \"@openbnb/mcp-server-airbnb\", \"--ignore-robots-txt\"],\n",
    "    client_session_timeout_seconds=30,\n",
    ")\n",
    "\n",
    "\n",
    "# This is a custom tool that we will provide to the agent. For the agent to use the tool, we must provide a docstring\n",
    "# and also have proper python typing for input and output parameters\n",
    "def send_message(message: str) -> str:\n",
    "    \"\"\"Display a message to the user and wait for their response.\n",
    "\n",
    "    Args:\n",
    "        message: str\n",
    "            The message to be displayed to the user.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the user.\n",
    "\n",
    "    \"\"\"\n",
    "    if os.environ.get(\"IN_PYTEST\") == \"1\":\n",
    "        return \"2 people, next weekend, low budget. Do not ask for any more information or confirmation.\"\n",
    "    return input(message + \" \")\n",
    "\n",
    "\n",
    "agent = AnyAgent.create(\n",
    "    \"tinyagent\",  # See all options in https://mozilla-ai.github.io/any-agent/\n",
    "    AgentConfig(\n",
    "        model_id=\"mistral:mistral-small-latest\",\n",
    "        tools=[airbnb_tool, time_tool, send_message],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "Now we've configured our agent, so it's time to run it! Since it has access to airbnb listings as well as the current time, it's a perfect fit for helping me find a nice airbnb for the weekend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I am looking to book an airbnb next weekend near Ohiopyle, PA. Can you help me plan this? Figure out the time, then ask me some questions and lets figure this out together. Once I tell you what you need to know, find and return some options for me.\n",
    "\"\"\"\n",
    "\n",
    "agent_trace = agent.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `agent.run` method returns an AgentTrace object, which has a few convenient attributes for displaying some interesting information about the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_trace.final_output)  # Final answer\n",
    "print(f\"Duration: {agent_trace.duration.total_seconds():.2f} seconds\")\n",
    "print(f\"Total Tokens: {agent_trace.tokens.total_tokens:,}\")\n",
    "print(f\"Total Cost (USD): {agent_trace.cost.total_cost:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
