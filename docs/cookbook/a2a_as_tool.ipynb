{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use an Agent as a tool for another agent.\n",
    "\n",
    "Multi-Agent systems are complicated! Enter the [A2A](https://github.com/google-a2a/A2A) protocol by Google: this protocol allows for simpler communication between agents, and easily enables the use of an agent as a tool for another agent. In this tutorial we'll show how you can create a few agents with any-agent and have an agent be provided as a tool for the other agent.\n",
    "\n",
    "This tutorial assumes basic familiarity with any-agent: if you haven't used any-agent before you may also find the [Creating your first agent](./../your_first_agent) cookbook to be useful. You also may find the other A2A related cookbook to be useful: [Serve an Agent with A2A](./../serve_a2a)\n",
    "\n",
    "\n",
    "Note: because this tutorial relies upon advanced stdio/stderr communication using the MCP Server, it cannot be run on Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "any-agent uses the python asyncio module to support async functionality. When running in Jupyter notebooks, this means we need to enable the use of nested event loops. We'll install any-agent and enable this below using nest_asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'any-agent[a2a]'\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# This notebook communicates with Mistral models using the Mistral API.\n",
    "if \"MISTRAL_API_KEY\" not in os.environ:\n",
    "    print(\"MISTRAL_API_KEY not found in environment!\")\n",
    "    api_key = getpass(\"Please enter your MISTRAL_API_KEY: \")\n",
    "    os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
    "    print(\"MISTRAL_API_KEY set for this session!\")\n",
    "else:\n",
    "    print(\"MISTRAL_API_KEY found in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the first two agents and serve them over A2A\n",
    "\n",
    "Let's give our first two \"helper\" agents some very simple capabilities. For this demo, we'll use the async method `agent.serve_async` so that we can easily run all of the agents from inside the notebook in a single python process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import httpx\n",
    "\n",
    "from any_agent import AgentConfig, AnyAgent\n",
    "from any_agent.config import MCPStdio\n",
    "from any_agent.serving import A2AServingConfig\n",
    "\n",
    "# This MCP Tool relies upon uvx https://docs.astral.sh/uv/getting-started/installation/\n",
    "time_tool = MCPStdio(\n",
    "    command=\"uvx\",\n",
    "    args=[\"mcp-server-time\", \"--local-timezone=America/New_York\"],\n",
    "    tools=[\n",
    "        \"get_current_time\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "time = await AnyAgent.create_async(\n",
    "    \"tinyagent\",  # See all options in https://mozilla-ai.github.io/any-agent/\n",
    "    AgentConfig(\n",
    "        model_id=\"mistral:mistral-small-latest\",\n",
    "        name=\"time_agent\",\n",
    "        description=\"I'm an agent to help with getting the time\",\n",
    "        tools=[time_tool],\n",
    "    ),\n",
    ")\n",
    "time_handle = await time.serve_async(A2AServingConfig(port=0, endpoint=\"/time\"))\n",
    "\n",
    "weather_expert = await AnyAgent.create_async(\n",
    "    \"tinyagent\",\n",
    "    AgentConfig(\n",
    "        model_id=\"mistral:mistral-small-latest\",\n",
    "        name=\"weather_expert\",\n",
    "        instructions=\"You're an expert that is an avid skier, recommend a great location to ski given a time of the year\",\n",
    "        description=\"I'm an agent that is an expert in recommending my favorite location given a time of the year\",\n",
    "    ),\n",
    ")\n",
    "weather_handle = await weather_expert.serve_async(\n",
    "    A2AServingConfig(port=0, endpoint=\"/location_recommender\")\n",
    ")\n",
    "\n",
    "weather_port = weather_handle.port\n",
    "time_port = time_handle.port\n",
    "\n",
    "max_attempts = 20\n",
    "poll_interval = 0.5\n",
    "attempts = 0\n",
    "time_url = f\"http://localhost:{time_port}\"\n",
    "weather_url = f\"http://localhost:{weather_port}\"\n",
    "async with httpx.AsyncClient() as client:\n",
    "    while True:\n",
    "        try:\n",
    "            # Try to make a basic GET request to check if server is responding\n",
    "            await client.get(time_url, timeout=1.0)\n",
    "            print(f\"Server is ready at {weather_url}\")\n",
    "            break\n",
    "        except (httpx.RequestError, httpx.TimeoutException):\n",
    "            # Server not ready yet, continue polling\n",
    "            pass\n",
    "\n",
    "        await asyncio.sleep(poll_interval)\n",
    "        attempts += 1\n",
    "        if attempts >= max_attempts:\n",
    "            msg = f\"Could not connect to the servers. Tried {max_attempts} times with {poll_interval} second interval.\"\n",
    "            raise ConnectionError(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and use the Third Agent \n",
    "\n",
    "Now that the first two agents are serving over A2A, our main agent can be given access to use it just like a tool! In order to do this you use the `a2a_tool_async` function which retrieves the info about the agent and allows you to call it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_agent import AgentConfig, AnyAgent\n",
    "from any_agent.tools import a2a_tool_async\n",
    "\n",
    "config = AgentConfig(\n",
    "    model_id=\"mistral:mistral-small-latest\",\n",
    "    instructions=\"Use the available tools to obtain additional information to answer the query.\",\n",
    "    description=\"The orchestrator that can use other agents via tools using the A2A protocol.\",\n",
    "    tools=[\n",
    "        await a2a_tool_async(\n",
    "            f\"http://localhost:{time_port}/time\",\n",
    "            http_kwargs={\n",
    "                \"timeout\": 30\n",
    "            },  # This gives the time agent up to 30 seconds to respond to each request\n",
    "        ),\n",
    "        await a2a_tool_async(\n",
    "            f\"http://localhost:{weather_port}/location_recommender\",\n",
    "            http_kwargs={\n",
    "                \"timeout\": 30\n",
    "            },  # This gives the weather agent up to 30 seconds to respond to each request\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "agent = await AnyAgent.create_async(\n",
    "    agent_framework=\"tinyagent\",\n",
    "    agent_config=config,\n",
    ")\n",
    "\n",
    "agent_trace = await agent.run_async(\"Where should I go this weekend to ski?\")\n",
    "\n",
    "print(agent_trace.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down the servers and the agents\n",
    "\n",
    "The following code can be used to gracefully shut down the agents that are serving via A2A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await time_handle.shutdown()\n",
    "await weather_handle.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
