{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your first agent\n",
    "\n",
    "[![Your first agent](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mozilla-ai/any-agent/blob/main/docs/cookbook/your_first_agent.ipynb) \n",
    "\n",
    "If you're looking to build your first agent using a few simple tools, this is a great place to start. In this cookbook example, we will create and run a simple agent that has access to a few web tools. This can be easily expanded to add more advanced tools and features. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "any-agent uses the python asyncio module to support async functionality. When running in Jupyter notebooks, this means we need to enable the use of nested event loops. We'll install any-agent and enable this below using nest_asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'any-agent'\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Agent\n",
    "\n",
    "Now it's time to configure the agent! At this stage you have a few choices:\n",
    "\n",
    "### Pick the framework\n",
    "\n",
    "We support a variety of underlying agent frameworks (OpenAI, Smolagents, Langchain, TinyAgent, etc), which all have their own particular agentic AI implementations. For this tutorial's simple use case, any of the frameworks should work just fine, but any-agent makes it easy to try out a different framework later, if we so choose. For this example, we will use the [TinyAgent](frameworks/tinyagent.md) framework.  \n",
    "\n",
    "### Pick an LLM\n",
    "\n",
    "Regardless of which agent framework you choose, each framework supports any-llm, which is a proxy that allows us to use whichever LLM inside the framework, hosted on by any provider. For example, we could use a local model via llama.cpp or llamafile, a google hosted gemini model, or a AWS bedrock hosted Llama model. For this example, let's use Mistral AI's mistral:mistral-small-latest LLM.\n",
    "\n",
    "### Pick which tools to use\n",
    "\n",
    " In this tutorial, we will provide the agent with access to web searches and web page visits. In later examples we will show more advanced tool usage like Model Context Protocol (MCP) tool use or inter-agent communication using Agent-2-Agent (A2A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "for key in (\"MISTRAL_API_KEY\", \"TAVILY_API_KEY\"):\n",
    "    if key not in os.environ:\n",
    "        print(f\"{key} not found in environment!\")\n",
    "        api_key = getpass(f\"Please enter your {key}: \")\n",
    "        os.environ[key] = api_key\n",
    "        print(f\"{key} set for this session!\")\n",
    "    else:\n",
    "        print(f\"{key} found in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Tavily web search. For it, you will need a (free) [Tavily API key](https://www.tavily.com/). Alternatively, you can import and use `search_web` (Duck Duck Go Search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_agent import AgentConfig, AnyAgent\n",
    "from any_agent.tools import search_tavily\n",
    "\n",
    "agent = AnyAgent.create(\n",
    "    \"tinyagent\",  # See all options in https://mozilla-ai.github.io/any-agent/\n",
    "    AgentConfig(model_id=\"mistral:mistral-small-latest\", tools=[search_tavily]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "Now we've configured our agent, so it's time to run it! Let's give it a simple task: find 5 trending new TV shows that were released recently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_trace = agent.run(\n",
    "    \"What are 5 tv shows that are trending in 2025? Check a few sites, and provide the name of the show, the exact release date, the genre, and a brief description of the show.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `agent.run` method returns an AgentTrace object, which has a few convenient attributes for displaying some interesting information about the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_trace.final_output)  # Final answer\n",
    "print(f\"Duration: {agent_trace.duration.total_seconds():.2f} seconds\")\n",
    "print(f\"Usage: {agent_trace.tokens.total_tokens:,}\")\n",
    "print(f\"Cost (USD): {agent_trace.cost.total_cost:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "any-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
