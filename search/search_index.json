{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"any-agent","text":"<p><code>any-agent</code> is a Python library providing a single interface to different agent frameworks.</p> <p>Warning</p> <p>Compared to traditional code-defined workflows, agent frameworks introduce complexity and demand much more computational power.</p> <p>Before jumping to use one, carefully consider and evaluate how much value you would get compared to manually defining a sequence of tools and LLM calls.</p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or newer</li> </ul>"},{"location":"#quickstart","title":"Quickstart","text":"<pre><code>pip install any-agent\n</code></pre> <p>To define any agent system you will always use the same imports:</p> <pre><code>from any_agent import AgentConfig, AnyAgent, TracingConfig\n</code></pre> <p>Note</p> <p>If you plan on using an agent that requires access to an external service (e.g. OpenAI, Mistral, DeepSeek, etc), you'll need to set any relevant environment variables, e.g.</p> <pre><code>export OPENAI_API_KEY=your_api_key_here\nexport DEEPSEEK_API_KEY=your_api_key_here\n</code></pre>"},{"location":"#single-agent","title":"Single Agent","text":"<pre><code>from any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"smolagents\",  # See all options in https://mozilla-ai.github.io/any-agent/frameworks/\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"Use the tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n    tracing=TracingConfig(output_dir=\"traces\") # Optional, but recommended for saving and viewing traces\n)\n\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"#multi-agent","title":"Multi-Agent","text":"<p>Warning</p> <p>A multi-agent system introduces even more complexity than a single agent.</p> <p>As stated before, carefully consider whether you need to adopt this pattern to solve the task.</p> <pre><code>from any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"smolagents\",  # See all options in https://mozilla-ai.github.io/any-agent/frameworks/\n    AgentConfig(\n        model_id=\"gpt-4.1-mini\",\n        instructions=\"You are the main agent. Use the other available agents to find an answer\",\n    ),\n    managed_agents=[\n        AgentConfig(\n            name=\"search_web_agent\",\n            description=\"An agent that can search the web\",\n            model_id=\"gpt-4.1-nano\",\n            tools=[search_web]\n        ),\n        AgentConfig(\n            name=\"visit_webpage_agent\",\n            description=\"An agent that can visit webpages\",\n            model_id=\"gpt-4.1-nano\",\n            tools=[visit_webpage]\n        )\n    ]\n)\n\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"#async","title":"Async","text":"<p>If you are running in <code>async</code> context, you should use the equivalent <code>create_async</code> and <code>run_async</code> methods:</p> <pre><code>import asyncio\nfrom any_agent.tools import search_web, visit_webpage\n\nasync def main():\n    agent = await AnyAgent.create_async(\n        \"openai\",\n        AgentConfig(\n            model_id=\"gpt-4.1-mini\",\n            instructions=\"You are the main agent. Use the other available agents to find an answer\",\n        ),\n        managed_agents=[\n            AgentConfig(\n                name=\"search_web_agent\",\n                description=\"An agent that can search the web\",\n                model_id=\"gpt-4.1-nano\",\n                tools=[search_web]\n            ),\n            AgentConfig(\n                name=\"visit_webpage_agent\",\n                description=\"An agent that can visit webpages\",\n                model_id=\"gpt-4.1-nano\",\n                tools=[visit_webpage]\n            )\n        ],\n        tracing=TracingConfig()\n    )\n\n    await agent.run_async(\"Which Agent Framework is the best??\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#any_agent.AnyAgent","title":"<code>any_agent.AnyAgent</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base abstract class for all agent implementations.</p> <p>This provides a unified interface for different agent frameworks.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>class AnyAgent(ABC):\n    \"\"\"Base abstract class for all agent implementations.\n\n    This provides a unified interface for different agent frameworks.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: AgentConfig,\n        managed_agents: Sequence[AgentConfig] | None = None,\n    ):\n        self.config = config\n        self.managed_agents = managed_agents\n        self.trace_filepath: str | None = None\n        self._mcp_servers: list[MCPServerBase] = []\n\n    async def _load_tools(\n        self, tools: Sequence[Tool]\n    ) -&gt; tuple[list[Any], list[MCPServerBase]]:\n        tools, mcp_servers = await wrap_tools(tools, self.framework)\n        # Add to agent so that it doesn't get garbage collected\n        self._mcp_servers.extend(mcp_servers)\n        for mcp_server in mcp_servers:\n            tools.extend(mcp_server.tools)\n        return tools, mcp_servers\n\n    @staticmethod\n    def _get_agent_type_by_framework(\n        framework_raw: AgentFramework | str,\n    ) -&gt; type[AnyAgent]:\n        framework = AgentFramework.from_string(framework_raw)\n\n        if framework is AgentFramework.SMOLAGENTS:\n            from any_agent.frameworks.smolagents import SmolagentsAgent\n\n            return SmolagentsAgent\n\n        if framework is AgentFramework.LANGCHAIN:\n            from any_agent.frameworks.langchain import LangchainAgent\n\n            return LangchainAgent\n\n        if framework is AgentFramework.OPENAI:\n            from any_agent.frameworks.openai import OpenAIAgent\n\n            return OpenAIAgent\n\n        if framework is AgentFramework.LLAMA_INDEX:\n            from any_agent.frameworks.llama_index import LlamaIndexAgent\n\n            return LlamaIndexAgent\n\n        if framework is AgentFramework.GOOGLE:\n            from any_agent.frameworks.google import GoogleAgent\n\n            return GoogleAgent\n\n        if framework is AgentFramework.AGNO:\n            from any_agent.frameworks.agno import AgnoAgent\n\n            return AgnoAgent\n\n        assert_never(framework)\n\n    @classmethod\n    def create(\n        cls,\n        agent_framework: AgentFramework | str,\n        agent_config: AgentConfig,\n        managed_agents: list[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ) -&gt; AnyAgent:\n        return asyncio.get_event_loop().run_until_complete(\n            cls.create_async(\n                agent_framework=agent_framework,\n                agent_config=agent_config,\n                managed_agents=managed_agents,\n                tracing=tracing,\n            )\n        )\n\n    @classmethod\n    async def create_async(\n        cls,\n        agent_framework: AgentFramework | str,\n        agent_config: AgentConfig,\n        managed_agents: list[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ) -&gt; AnyAgent:\n        framework = AgentFramework.from_string(agent_framework)\n        agent_cls = cls._get_agent_type_by_framework(agent_framework)\n        agent = agent_cls(agent_config, managed_agents=managed_agents)\n        if tracing is not None:\n            # Agno not yet supported https://github.com/Arize-ai/openinference/issues/1302\n            # Google ADK not yet supported https://github.com/Arize-ai/openinference/issues/1506\n            if framework in (AgentFramework.AGNO, AgentFramework.GOOGLE):\n                logger.warning(\n                    \"Tracing is not yet supported for AGNO and GOOGLE frameworks. \"\n                )\n            else:\n                agent.trace_filepath = setup_tracing(framework, tracing)\n        await agent.load_agent()\n        return agent\n\n    def run(self, prompt: str) -&gt; Any:\n        \"\"\"Run the agent with the given prompt.\"\"\"\n        return asyncio.get_event_loop().run_until_complete(self.run_async(prompt))\n\n    @abstractmethod\n    async def load_agent(self) -&gt; None:\n        \"\"\"Load the agent instance.\"\"\"\n\n    @abstractmethod\n    async def run_async(self, prompt: str) -&gt; Any:\n        \"\"\"Run the agent asynchronously with the given prompt.\"\"\"\n\n    @property\n    @abstractmethod\n    def framework(self) -&gt; AgentFramework:\n        \"\"\"The Agent Framework used\"\"\"\n\n    @property\n    def agent(self) -&gt; Any:\n        \"\"\"The underlying agent implementation from the framework.\n\n        This property is intentionally restricted to maintain framework abstraction\n        and prevent direct dependency on specific agent implementations.\n\n        If you need functionality that relies on accessing the underlying agent:\n        1. Consider if the functionality can be added to the AnyAgent interface\n        2. Submit a GitHub issue describing your use case\n        3. Contribute a PR implementing the needed functionality\n\n        Raises:\n            NotImplementedError: Always raised when this property is accessed\n\n        \"\"\"\n        msg = \"Cannot access the 'agent' property of AnyAgent, if you need to use functionality that relies on the underlying agent framework, please file a Github Issue or we welcome a PR to add the functionality to the AnyAgent class\"\n        raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#any_agent.AnyAgent.agent","title":"<code>agent</code>  <code>property</code>","text":"<p>The underlying agent implementation from the framework.</p> <p>This property is intentionally restricted to maintain framework abstraction and prevent direct dependency on specific agent implementations.</p> <p>If you need functionality that relies on accessing the underlying agent: 1. Consider if the functionality can be added to the AnyAgent interface 2. Submit a GitHub issue describing your use case 3. Contribute a PR implementing the needed functionality</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Always raised when this property is accessed</p>"},{"location":"api/#any_agent.AnyAgent.framework","title":"<code>framework</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The Agent Framework used</p>"},{"location":"api/#any_agent.AnyAgent.load_agent","title":"<code>load_agent()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Load the agent instance.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@abstractmethod\nasync def load_agent(self) -&gt; None:\n    \"\"\"Load the agent instance.\"\"\"\n</code></pre>"},{"location":"api/#any_agent.AnyAgent.run","title":"<code>run(prompt)</code>","text":"<p>Run the agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>def run(self, prompt: str) -&gt; Any:\n    \"\"\"Run the agent with the given prompt.\"\"\"\n    return asyncio.get_event_loop().run_until_complete(self.run_async(prompt))\n</code></pre>"},{"location":"api/#any_agent.AnyAgent.run_async","title":"<code>run_async(prompt)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Run the agent asynchronously with the given prompt.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@abstractmethod\nasync def run_async(self, prompt: str) -&gt; Any:\n    \"\"\"Run the agent asynchronously with the given prompt.\"\"\"\n</code></pre>"},{"location":"api/#any_agent.AgentFramework","title":"<code>any_agent.AgentFramework</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentFramework(str, Enum):\n    GOOGLE = auto()\n    LANGCHAIN = auto()\n    LLAMA_INDEX = auto()\n    OPENAI = auto()\n    AGNO = auto()\n    SMOLAGENTS = auto()\n\n    @classmethod\n    def from_string(cls, value: str | Self) -&gt; Self:\n        if isinstance(value, cls):\n            return value\n\n        formatted_value = value.strip().upper()\n        if formatted_value not in cls.__members__:\n            error_message = (\n                f\"Unsupported agent framework: '{value}'. \"\n                f\"Valid frameworks are: {list(cls.__members__.keys())}\"\n            )\n            raise ValueError(error_message)\n\n        return cls[formatted_value]\n</code></pre>"},{"location":"api/#any_agent.AgentConfig","title":"<code>any_agent.AgentConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentConfig(BaseModel):\n    model_config = ConfigDict(extra=\"forbid\")\n    model_id: str\n    api_base: str | None = None\n    api_key: str | None = None\n    description: str | None = None\n    name: str = \"any_agent\"\n    instructions: str | None = None\n    tools: Sequence[Tool] = Field(default_factory=list)\n    handoff: bool = False\n    agent_type: str | None = None\n    agent_args: MutableMapping[str, Any] | None = None\n    model_type: str | None = None\n    model_args: MutableMapping[str, Any] | None = None\n</code></pre>"},{"location":"api/#any_agent.config.MCPStdioParams","title":"<code>any_agent.config.MCPStdioParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class MCPStdioParams(BaseModel):\n    command: str\n    args: Sequence[str]\n    tools: Sequence[str] | None = None\n    client_session_timeout_seconds: float | None = 5\n    \"\"\"the read timeout passed to the MCP ClientSession.\"\"\"\n\n    model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"api/#any_agent.config.MCPStdioParams.client_session_timeout_seconds","title":"<code>client_session_timeout_seconds = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>the read timeout passed to the MCP ClientSession.</p>"},{"location":"api/#any_agent.config.MCPSseParams","title":"<code>any_agent.config.MCPSseParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class MCPSseParams(BaseModel):\n    url: str\n    headers: Mapping[str, str] | None = None\n    tools: Sequence[str] | None = None\n    client_session_timeout_seconds: float | None = 5\n    \"\"\"the read timeout passed to the MCP ClientSession.\"\"\"\n\n    model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"api/#any_agent.config.MCPSseParams.client_session_timeout_seconds","title":"<code>client_session_timeout_seconds = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>the read timeout passed to the MCP ClientSession.</p>"},{"location":"api/#any_agent.config.TracingConfig","title":"<code>any_agent.config.TracingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class TracingConfig(BaseModel):\n    model_config = ConfigDict(extra=\"forbid\")\n    output_dir: str | None = \"traces\"  # None for no json saved trace\n    llm: str | None = \"yellow\"\n    tool: str | None = \"blue\"\n    agent: str | None = None\n    chain: str | None = None\n</code></pre>"},{"location":"api/#any_agent.tools","title":"<code>any_agent.tools</code>","text":""},{"location":"api/#any_agent.tools.ask_user_verification","title":"<code>ask_user_verification(query)</code>","text":"<p>Asks user to verify the given <code>query</code>.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The question that requires verification.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def ask_user_verification(query: str) -&gt; str:\n    \"\"\"Asks user to verify the given `query`.\n\n    Args:\n        query: The question that requires verification.\n\n    \"\"\"\n    return input(f\"{query} =&gt; Type your answer here:\")\n</code></pre>"},{"location":"api/#any_agent.tools.search_web","title":"<code>search_web(query)</code>","text":"<p>Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query to perform.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The top search results.</p> Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\n\n    Args:\n        query (str): The search query to perform.\n\n    Returns:\n        The top search results.\n\n    \"\"\"\n    ddgs = DDGS()\n    results = ddgs.text(query, max_results=10)\n    return \"\\n\".join(\n        f\"[{result['title']}]({result['href']})\\n{result['body']}\" for result in results\n    )\n</code></pre>"},{"location":"api/#any_agent.tools.send_console_message","title":"<code>send_console_message(user, query)</code>","text":"<p>Sends the specified user a message via console and returns their response.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The question to ask the user.</p> required <code>user</code> <code>str</code> <p>The user to ask the question to.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The user's response.</p> Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def send_console_message(user: str, query: str) -&gt; str:\n    \"\"\"Sends the specified user a message via console and returns their response.\n\n    Args:\n        query: The question to ask the user.\n        user: The user to ask the question to.\n\n    Returns:\n        str: The user's response.\n\n    \"\"\"\n    return input(f\"{query}\\n{user}&gt;&gt;\")\n</code></pre>"},{"location":"api/#any_agent.tools.show_final_answer","title":"<code>show_final_answer(answer)</code>","text":"<p>Show the final answer to the user.</p> <p>Parameters:</p> Name Type Description Default <code>answer</code> <code>str</code> <p>The final answer.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_final_answer(answer: str) -&gt; str:\n    \"\"\"Show the final answer to the user.\n\n    Args:\n        answer: The final answer.\n\n    \"\"\"\n    logger.info(f\"Final answer: {answer}\")\n    return answer\n</code></pre>"},{"location":"api/#any_agent.tools.show_plan","title":"<code>show_plan(plan)</code>","text":"<p>Show the current plan to the user.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>str</code> <p>The current plan.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_plan(plan: str) -&gt; str:\n    \"\"\"Show the current plan to the user.\n\n    Args:\n        plan: The current plan.\n\n    \"\"\"\n    logger.info(f\"Current plan: {plan}\")\n    return plan\n</code></pre>"},{"location":"api/#any_agent.tools.visit_webpage","title":"<code>visit_webpage(url)</code>","text":"<p>Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The url of the webpage to visit.</p> required Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def visit_webpage(url: str) -&gt; str:\n    \"\"\"Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.\n\n    Args:\n        url: The url of the webpage to visit.\n\n    \"\"\"\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n\n        markdown_content = markdownify(response.text).strip()  # type: ignore[no-untyped-call]\n\n        markdown_content = re.sub(r\"\\n{2,}\", \"\\n\", markdown_content)\n\n        return _truncate_content(markdown_content, 10000)\n    except RequestException as e:\n        return f\"Error fetching the webpage: {e!s}\"\n    except Exception as e:\n        return f\"An unexpected error occurred: {e!s}\"\n</code></pre>"},{"location":"api/#any_agent.tools.wrap_mcp_server","title":"<code>wrap_mcp_server(mcp_tool, agent_framework)</code>  <code>async</code>","text":"<p>Generic MCP server wrapper that can work with different frameworks based on the specified agent_framework</p> Source code in <code>src/any_agent/tools/wrappers.py</code> <pre><code>async def wrap_mcp_server(\n    mcp_tool: MCPParams,\n    agent_framework: AgentFramework,\n) -&gt; MCPServerBase:\n    \"\"\"Generic MCP server wrapper that can work with different frameworks\n    based on the specified agent_framework\n    \"\"\"\n    manager = get_mcp_server(mcp_tool, agent_framework)\n    await manager.setup_tools()\n\n    return manager\n</code></pre>"},{"location":"api/#any_agent.tracing","title":"<code>any_agent.tracing</code>","text":""},{"location":"api/#any_agent.tracing.setup_tracing","title":"<code>setup_tracing(agent_framework, tracing_config)</code>","text":"<p>Setup tracing for <code>agent_framework</code> using <code>openinference.instrumentation</code>.</p> <p>Parameters:</p> Name Type Description Default <code>agent_framework</code> <code>AgentFramework</code> <p>The type of agent being used.</p> required <code>tracing_config</code> <code>TracingConfig</code> <p>Configuration for tracing, including output directory and styles.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the JSON file where traces will be stored.</p> Source code in <code>src/any_agent/tracing.py</code> <pre><code>def setup_tracing(\n    agent_framework: AgentFramework,\n    tracing_config: TracingConfig,\n) -&gt; str:\n    \"\"\"Setup tracing for `agent_framework` using `openinference.instrumentation`.\n\n    Args:\n        agent_framework (AgentFramework): The type of agent being used.\n        tracing_config (TracingConfig): Configuration for tracing, including output directory and styles.\n\n    Returns:\n        str: The name of the JSON file where traces will be stored.\n\n    \"\"\"\n\n    agent_framework_ = AgentFramework.from_string(agent_framework)\n\n    tracer_provider, file_name = _get_tracer_provider(\n        agent_framework,\n        tracing_config,\n    )\n\n    instrumenter = get_instrumenter_by_framework(agent_framework_)\n    instrumenter.instrument(tracer_provider=tracer_provider)\n\n    return file_name\n</code></pre>"},{"location":"evaluation/","title":"Agent Evaluation","text":"<p>Warning</p> <p>The codebase for evaluation is under development and is not yet stable. Use with caution, we welcome contributions.</p> <p>Evaluation using any_agent.evaluation is designed to be a \"trace-first\" evaluation. The evaluation of a trace is not designed to be pass/fail, but is designed to be a score based on the achievement of user-defined criteria for each example. Agent systems are hyper-specific to each use case, and it's difficult to provide a single set of metrics that would reliably provide the insight needed to make a decision about the effectiveness of an agent.</p> <p>Using any-agent evaluation, you can specify any criteria you wish, and through LLM-as-a-judge technology, any-agent will evaluate which criteria are satisfied.</p>"},{"location":"evaluation/#example","title":"Example","text":"<p>Using the unified tracing format provided by any-agent's tracing functionality, the trace can be evaluated with user defined criteria. The steps for evaluating an agent are as follows:</p> <ol> <li>Run an agent using any-agent, which will produce a json file with the trace. For example</li> </ol> <p><pre><code>from any_agent import AgentConfig, AnyAgent, TracingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n    \"langchain\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\",\n        tools=[search_web]\n    ),\n    tracing=TracingConfig(output_dir=\"traces\")\n)\n\nagent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")\n</code></pre> 1. Define a test case in a yaml file, e.g.</p> <pre><code># The criteria will be passed to an llm-as-a-judge along with the trace to have as context\n# The points specify the weight given to each criteria when producing the final score\nllm_judge: openai/gpt-4o\ncheckpoints:\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to retrieve the length of Pont des Arts\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to access the top speed of a leopard\n  - points: 1\n    criteria: |\n        Ensure that the agent ran a python snippet to combine the information\n        from the info retrieved from the web searches\n\n# Optionally, you can check whether the final answer is what was expected. Checking this value does not use an LLM\nground_truth:\n  - name: Time\n    points: 5\n    value: 9.63\n</code></pre> <ol> <li>Run the evaluation using the test case and trace. <pre><code>from any_agent.evaluation.test_case import TestCase\nfrom any_agent.evaluation.evaluate import evaluate_telemetry\ntest_case = TestCase.from_yaml(\"./docs/examples/test_case.yaml\")\nevaluate_telemetry(test_case, '/path/to/telemetry/output')\n</code></pre> The output will look something like this:</li> </ol> <pre><code>Passed:\n- Ensure that the agent called the search_web tool in order to retrieve the length of Pont des Arts\n- The agent called the search_web tool with the query 'Pont des Arts length' as indicated in the telemetry evidence.\n\nPassed:\n- Ensure that the agent ran a python snippet to combine the information from the info retrieved from the web searches\n- The agent successfully ran a Python snippet to calculate the time it would take for a leopard to run through the Pont des Arts using the length of the bridge retrieved from a web search.\n\nFailed:\n- Ensure that the agent called the search_web tool in order to access the top speed of a leopard\n- The agent called the search_web tool to find the length of Pont des Arts, but did not call it to access the top speed of a leopard.\n\nFailed:\n- Check if Time is approximately '9.63'.\n- The calculated time in the agent's answer is 9.62, not 9.63.\n\nFailed:\n- Is the answer a direct match?\n- Partial Match (F1) score is 0.0\nPassed checkpoints: 2\nFailed checkpoints: 3\n=====================================\nScore: 2/9\n=====================================\n\nReading existing output from output/results.json\nWriting output to output/results.json\n</code></pre>"},{"location":"frameworks/","title":"Agent Frameworks","text":"<p>Here you can find the frameworks currently supported in <code>any-agent</code>, along with some basic examples.</p> <p>Info</p> <p>If you are missing any agent framework, check the existing issues to see if it has been already requested and comment/upvote on that issue.</p> <p>If there is no existing issue, don't hesitate to request and/or contribute it.</p>"},{"location":"frameworks/#examples","title":"Examples","text":"Google ADK\ud83e\udd9c\ud83d\udd17 LangChain\ud83d\uddc2\ufe0f LlamaIndex \ud83e\udd99OpenAI Agents SDK\ud83e\udd17 smolagentsAgno Agents <p>Google ADK Repo</p> <pre><code>from any_agent import AnyAgent, AgentConfig\nagent = AnyAgent.create(\n    \"google\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>LangChain Repo</p> <pre><code>agent = AnyAgent.create(\n    \"langchain\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>LLamaIndex Repo</p> <pre><code>agent = AnyAgent.create(\n    \"llama_index\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>OpenAI Agents Repo</p> <pre><code>agent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>smolagents Repo</p> <pre><code>agent = AnyAgent.create(\n    \"smolagents\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>Agno Agents Repo</p> <pre><code>agent = AnyAgent.create(\n    \"agno\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\"\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"frameworks/#models","title":"Models","text":"<p>The model used by an agent is defined by a few arguments: <code>model_id</code>, <code>model_type</code>, <code>model_args</code>, <code>api_base</code>, and <code>api_key</code>.</p> <pre><code>import os\nfrom any_agent import AnyAgent, AgentFramework, AgentConfig\nagent = AnyAgent.create(\n    \"smolagents\",\n    AgentConfig(\n        model_id=\"llama3.2\",\n        model_args={\"temperature\": 1},\n        api_base=\"http://localhost:11434/v1\", # optional\n        api_key=os.getenv('MY_CUSTOM_KEY_ENV'), # optional, litellm will automatically search for OPENAI_API_KEY etc\n    )\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre> <p>If you just specify <code>model_id</code> (as in the examples above), the agent will use the default <code>model_type</code> that we have selected for that framework and no <code>model_args</code>.</p>"},{"location":"frameworks/#model-type","title":"Model Type","text":"<p>The <code>model_type</code> parameter controls the type of model class that is used by the agent framework, and is unique to the agent framework being used. For each framework, we leverage their support for <code>LiteLLM</code> and when relevant use it as default <code>model_type</code>, allowing you to use the same <code>model_id</code> syntax across these frameworks.</p>"},{"location":"frameworks/#model-id","title":"Model ID","text":"<p>If you are using the default <code>model_type</code> (LiteLLM), you can refer to LiteLLM Provider Docs for the list of providers and how to access them.</p>"},{"location":"frameworks/#model-args","title":"Model Args","text":"<p>The <code>model_args</code> provides the ability to set parameters like <code>temperature</code>, <code>top_k</code>, as well as any other provider-specific parameters. Refer to LiteLLM Completion API Docs as well</p>"},{"location":"instructions/","title":"Agent Instructions (aka System Prompt)","text":"<p><code>any-agent</code> allows you to specify the instruction for the agent (often also referred to as a \"system_prompt\").</p> <p>Warning</p> <p>Some frameworks use complex default instructions for specific agent implementations. Completely replacing those instructions might result in unexpected behavior.</p> <p>In those cases, you might want to instead copy-paste and extend the default instructions. For example, check the <code>CodeAgent</code> default instructions in <code>smolagents</code>.</p> <pre><code>from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\nfrom any_agent import AgentConfig\n\ninstruction = RECOMMENDED_PROMPT_PREFIX + \"\\nYou are a helpful assistant that can navigate the web.\"\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    instructions=instruction,\n)\n</code></pre>"},{"location":"tools/","title":"Agent Tools","text":"<p><code>any-agent</code> provides 2 options to specify what <code>tools</code> are available to your agent: <code>Callable</code>, or <code>MCP</code> (Model Context Protocol).</p> <p>You can use any combination of options in the same agent.</p> <p>Under the hood, <code>any-agent</code> takes care of wrapping the tool so it becomes usable by the selected framework.</p> <p>MCP can either be run locally (MCPStdio) or you can connect to an MCP that is running elsewhere (MCPSse). See SuperGateway for an easy way to turn a Stdio server into an SSE server.</p> CallableMCP (Stdio)MCP (SSE) <pre><code>from any_agent import AgentConfig\nfrom any_agent.tools import search_web\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[search_web]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig\nfrom any_agent.config import MCPStdioParams\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        MCPStdioParams(\n            command=\"docker\",\n            args=[\"run\", \"-i\", \"--rm\", \"mcp/fetch\"],\n            tools=[\"fetch\"]\n        ),\n    ]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig\nfrom any_agent.config import MCPSseParams\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        MCPSseParams(\n            url=\"http://localhost:8000/sse\"\n        ),\n    ]\n)\n</code></pre>"},{"location":"tracing/","title":"Agent Tracing","text":"<p><code>any-agent</code> uses <code>openinference</code> to generate standardized OpenTelemetry traces for any of the supported agent frameworks.</p>"},{"location":"tracing/#example","title":"Example","text":"<p>To enable tracing, add a TracingConfig object <code>TracingConfig</code> when creating an agent</p> <pre><code>from any_agent import AgentConfig, AnyAgent, TracingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n        \"openai\",\n        agent_config=AgentConfig(\n                model_id=\"gpt-4o\",\n                tools=[search_web],\n        ),\n        tracing=TracingConfig()\n      )\nagent.run(\"Which agent framework is the best?\")\n</code></pre>"},{"location":"tracing/#outputs","title":"Outputs","text":"<p>Tracing will output standardized console output regardless of the framework used, and will also save the trace as a json file in the directory set by the TracingConfig object. The file path of the trace is stored in the Agent.trace_filepath member variable.</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 LLM \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ninput: Which agent framework is the best?\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 TOOL \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntool_name: search_web\ninput: {'query': 'best agent framework 2023'}\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Output \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ... The agent architecture came to life in March 2023, but it wasn't until a few    \u2502\n\u2502 months later that it took a grip in the open-source community. The agent landscape may still seem like a \"mad scientist\" kind of experiment, but there are \u2502\n\u2502 already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks Top 10 AI Agent Frameworks - gocodeo.com The    \u2502\n\u2502 ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog     \u2502\n\u2502 Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \"just prompt it and see what happens.\" As AI     \u2502\n\u2502 agents inch closer to production ... List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ... 3. Bee Agent Framework (IBM) Introduction:    \u2502\n\u2502 The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to  \u2502\n\u2502 integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ... Top 9  \u2502\n\u2502 AI Agent Frameworks as of April 2025 | Shakudo AutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by   \u2502\n\u2502 automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build,  \u2502\n\u2502 fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ... 10 best AI    \u2502\n\u2502 agent frameworks - blog.apify.com Best AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a      \u2502\n\u2502 scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it  \u2502\n\u2502 easier to integrate with third-party tools, handle cloud hosting, monitor ... Best 5 Frameworks To Build Multi-Agent AI Applications In this example, we   \u2502\n\u2502 specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run                       \u2502\n\u2502 reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework     \u2502\n\u2502 recently released by OpenAI. It is a lightweight multi-agent orchestration framework. Agentic Framework Showdown: We Tested 8 AI Agent Frameworks They     \u2502\n\u2502 reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of    \u2502\n\u2502 the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI;      \u2502\n\u2502 Langflow; LangGraph; LlamaIndex; n8n ... Comparing Open-Source AI Agent Frameworks - Langfuse Blog This post offers an in-depth look at some of the        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre> <p>In addition, an output JSON will be stored in the selected <code>output_dir</code>, which is <code>\"traces\"</code> by default:</p> <pre><code>[\n  {\n    \"name\": \"response\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xd4a8cd952e71e1d1\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:25.327409Z\",\n    \"end_time\": \"2025-04-07T10:20:26.813604Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"output.mime_type\": \"application/json\",\n      \"output.value\": \"{\\\"id\\\":\\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\",\\\"created_at\\\":1744021218.0,\\\"error\\\":null,\\\"incomplete_details\\\":null,\\\"instructions\\\":\\\"Search the web to answer\\\",\\\"metadata\\\":{},\\\"model\\\":\\\"gpt-4o-2024-08-06\\\",\\\"object\\\":\\\"response\\\",\\\"output\\\":[{\\\"arguments\\\":\\\"{\\\\\\\"query\\\\\\\":\\\\\\\"best agent framework 2023\\\\\\\"}\\\",\\\"call_id\\\":\\\"call_xCZMfOtnbmKS1nGDywFtmCcR\\\",\\\"name\\\":\\\"search_web\\\",\\\"type\\\":\\\"function_call\\\",\\\"id\\\":\\\"fc_67f3a6e351988192a79ec42d68fccbe001e7f8b6e38c7e7a\\\",\\\"status\\\":\\\"completed\\\"}],\\\"parallel_tool_calls\\\":false,\\\"temperature\\\":1.0,\\\"tool_choice\\\":\\\"auto\\\",\\\"tools\\\":[{\\\"name\\\":\\\"search_web\\\",\\\"parameters\\\":{\\\"properties\\\":{\\\"query\\\":{\\\"description\\\":\\\"The search query to perform.\\\",\\\"title\\\":\\\"Query\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"],\\\"title\\\":\\\"search_web_args\\\",\\\"type\\\":\\\"object\\\",\\\"additionalProperties\\\":false},\\\"strict\\\":true,\\\"type\\\":\\\"function\\\",\\\"description\\\":\\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\"}],\\\"top_p\\\":1.0,\\\"max_output_tokens\\\":null,\\\"previous_response_id\\\":null,\\\"reasoning\\\":{\\\"effort\\\":null,\\\"generate_summary\\\":null},\\\"status\\\":\\\"completed\\\",\\\"text\\\":{\\\"format\\\":{\\\"type\\\":\\\"text\\\"}},\\\"truncation\\\":\\\"disabled\\\",\\\"usage\\\":{\\\"input_tokens\\\":89,\\\"input_tokens_details\\\":{\\\"cached_tokens\\\":0},\\\"output_tokens\\\":20,\\\"output_tokens_details\\\":{\\\"reasoning_tokens\\\":0},\\\"total_tokens\\\":109},\\\"user\\\":null,\\\"store\\\":true}\",\n      \"llm.tools.0.tool.json_schema\": \"{\\\"type\\\": \\\"function\\\", \\\"function\\\": {\\\"name\\\": \\\"search_web\\\", \\\"description\\\": \\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\", \\\"parameters\\\": {\\\"properties\\\": {\\\"query\\\": {\\\"description\\\": \\\"The search query to perform.\\\", \\\"title\\\": \\\"Query\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"query\\\"], \\\"title\\\": \\\"search_web_args\\\", \\\"type\\\": \\\"object\\\", \\\"additionalProperties\\\": false}, \\\"strict\\\": true}}\",\n      \"llm.token_count.completion\": 89,\n      \"llm.token_count.prompt\": 20,\n      \"llm.token_count.total\": 109,\n      \"llm.output_messages.0.message.role\": \"assistant\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.id\": \"call_xCZMfOtnbmKS1nGDywFtmCcR\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.name\": \"search_web\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.arguments\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"llm.input_messages.0.message.role\": \"system\",\n      \"llm.input_messages.0.message.content\": \"Search the web to answer\",\n      \"llm.model_name\": \"gpt-4o-2024-08-06\",\n      \"llm.invocation_parameters\": \"{\\\"id\\\": \\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\", \\\"created_at\\\": 1744021218.0, \\\"instructions\\\": \\\"Search the web to answer\\\", \\\"metadata\\\": {}, \\\"model\\\": \\\"gpt-4o-2024-08-06\\\", \\\"object\\\": \\\"response\\\", \\\"parallel_tool_calls\\\": false, \\\"temperature\\\": 1.0, \\\"tool_choice\\\": \\\"auto\\\", \\\"top_p\\\": 1.0, \\\"reasoning\\\": {}, \\\"status\\\": \\\"completed\\\", \\\"text\\\": {\\\"format\\\": {\\\"type\\\": \\\"text\\\"}}, \\\"truncation\\\": \\\"disabled\\\", \\\"store\\\": true}\",\n      \"input.mime_type\": \"application/json\",\n      \"input.value\": \"[{\\\"content\\\": \\\"Which agent framework is the best?\\\", \\\"role\\\": \\\"user\\\"}]\",\n      \"llm.input_messages.1.message.role\": \"user\",\n      \"llm.input_messages.1.message.content\": \"Which agent framework is the best?\",\n      \"openinference.span.kind\": \"LLM\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n  {\n    \"name\": \"search_web\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xe8fa92007caee376\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:26.821732Z\",\n    \"end_time\": \"2025-04-07T10:20:28.420378Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"tool.name\": \"search_web\",\n      \"input.value\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"input.mime_type\": \"application/json\",\n      \"output.value\": \"[Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ...](https://www.taskade.com/blog/top-autonomous-agents/)\\nThe agent architecture came to life in March 2023, but it wasn't until a few months later that it took a grip in the open-source community. The agent landscape may still seem like a \\\"mad scientist\\\" kind of experiment, but there are already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks\\n[Top 10 AI Agent Frameworks - gocodeo.com](https://www.gocodeo.com/post/top-10-ai-agent-frameworks)\\nThe ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \\\"just prompt it and see what happens.\\\" As AI agents inch closer to production ...\\n[List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ...](https://www.devopsschool.com/blog/list-of-top-10-multi-agent-orchestrator-frameworks-for-deploying-ai-agents/)\\n3. Bee Agent Framework (IBM) Introduction: The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ...\\n[Top 9 AI Agent Frameworks as of April 2025 | Shakudo](https://www.shakudo.io/blog/top-9-ai-agent-frameworks)\\nAutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build, fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ...\\n[10 best AI agent frameworks - blog.apify.com](https://blog.apify.com/10-best-ai-agent-frameworks/)\\nBest AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it easier to integrate with third-party tools, handle cloud hosting, monitor ...\\n[Best 5 Frameworks To Build Multi-Agent AI Applications](https://getstream.io/blog/multiagent-ai-frameworks/)\\nIn this example, we specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework recently released by OpenAI. It is a lightweight multi-agent orchestration framework.\\n[Agentic Framework Showdown: We Tested 8 AI Agent Frameworks](https://www.willowtreeapps.com/craft/8-agentic-frameworks-tested)\\nThey reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI; Langflow; LangGraph; LlamaIndex; n8n ...\\n[Comparing Open-Source AI Agent Frameworks - Langfuse Blog](https://langfuse.com/blog/2025-03-19-ai-agent-comparison)\\nThis post offers an in-depth look at some of the leading open-source AI agent frameworks out there: LangGraph, the OpenAI Agents SDK, Smolagents, CrewAI, AutoGen, Semantic Kernel, and LlamaIndex agents. By the time you finish reading, you should have a clearer view of each framework's sweet spot, how they differ, and where they excel in real ...\\n[Choosing the Right AI Agent Framework: LangGraph vs CrewAI vs OpenAI Swarm](https://www.relari.ai/blog/ai-agent-framework-comparison-langgraph-crewai-openai-swarm)\\nWe chose LangGraph, CrewAI, and OpenAI Swarm because they represent the latest schools of thought in agent development. Here's a quick overview: LangGraph: As its name suggests, LangGraph bets on graph architecture as the best way to define and orchestrate agentic workflows. Unlike early versions of LangChain, LangGraph is a well designed framework with many robust and customizable features ...\\n[Best AI Agent Frameworks](https://www.folio3.ai/blog/ai-agent-frameworks/)\\nYour business demands the best AI agent framework to accelerate your project. It should support LLM integration, advanced reasoning, long-term memory, flexible tool coordination, and smooth collaboration between multiple agents. Here we discuss some AI agent frameworks that empower you to achieve unmatched levels of automation and intelligence.\",\n      \"openinference.span.kind\": \"TOOL\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n</code></pre>"}]}